{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f037f32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SentenceTransformer model...\n",
      "Number of users: 536829\n",
      "Number of users with at least 5 high ratings: 418829\n",
      "\n",
      "Generating neural network embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830d13bc7cd449f2af974a260736b2af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/869 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (27780, 384)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "DATA = Path(\"./data\")\n",
    "\n",
    "GEN_DATA = DATA / \"gen\"\n",
    "RAW_DATA = DATA / \"raw\"\n",
    "game_data = pl.read_csv(RAW_DATA / \"games_detailed_info2025.csv\")\n",
    "\n",
    "game_data = game_data.with_columns(pl.col(\"description\").fill_null(\"\"))\n",
    "# game_data = game_data.sample(fraction=1)\n",
    "\n",
    "game_data.head()\n",
    "\n",
    "# Load SentenceTransformer model for neural embeddings\n",
    "print(\"Loading SentenceTransformer model...\")\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "data_path = Path(\"data\")\n",
    "review_data = pl.read_csv(data_path / \"raw\" / \"bgg-26m-reviews.csv\")\n",
    "\n",
    "review_data = review_data.filter(pl.col(\"rating\") >= 8)\n",
    "user_data = review_data.group_by(\"user\").agg(\n",
    "    pl.len().alias(\"len\"),\n",
    "    pl.col(\"ID\"),\n",
    ")\n",
    "# keep only users with at least 5 reviews\n",
    "print(f\"Number of users: {user_data.height}\")\n",
    "user_data = user_data.filter(pl.col(\"len\") > 1)\n",
    "print(f\"Number of users with at least 5 high ratings: {user_data.height}\")\n",
    "\n",
    "# Generate neural network embeddings using SentenceTransformer\n",
    "descriptions = game_data[\"description\"].fill_null(\"\").to_list()\n",
    "\n",
    "print(\"\\nGenerating embeddings...\")\n",
    "reduced_X = model.encode(\n",
    "    descriptions,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(f\"Embedding shape: {reduced_X.shape}\")\n",
    "print()\n",
    "\n",
    "index_to_id = {index: id for index, id in enumerate(game_data[\"id\"])}\n",
    "id_to_index = {v: k for k, v in index_to_id.items()}\n",
    "\n",
    "# Nearest Neighbors model\n",
    "nbrs = NearestNeighbors(n_neighbors=11, metric=\"cosine\").fit(reduced_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7ae1c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 418829 user baskets...\n",
      "Generated embeddings for 418809 users (dropped 20 users with no valid items).\n"
     ]
    }
   ],
   "source": [
    "def compute_basket_embeddings_train_only(baskets, item_vectors, id_map):\n",
    "    user_vectors = []\n",
    "    valid_user_indices = []\n",
    "\n",
    "    valid_ids_set = set(id_map.keys())\n",
    "    print(f\"Processing {len(baskets)} user baskets...\")\n",
    "\n",
    "    for i, basket in enumerate(baskets):\n",
    "        length = len(basket)\n",
    "        if length == 0:\n",
    "            continue\n",
    "\n",
    "        # Split: 30% test, 70% train\n",
    "        split_point = int(np.ceil(0.3 * length))\n",
    "        train_items = basket[split_point:]  # remaining 70% for centroid\n",
    "\n",
    "        # Only keep train items that exist in id_map\n",
    "        train_valid_indices = [id_map[item] for item in train_items if item in valid_ids_set]\n",
    "\n",
    "        if train_valid_indices:\n",
    "            # Compute centroid from train items only\n",
    "            train_vecs = item_vectors[train_valid_indices]\n",
    "            user_vec = np.mean(train_vecs, axis=0)\n",
    "\n",
    "            user_vectors.append(user_vec)\n",
    "            valid_user_indices.append(i)\n",
    "\n",
    "    return np.array(user_vectors), valid_user_indices\n",
    "\n",
    "\n",
    "user_baskets = user_data[\"ID\"].to_list()\n",
    "\n",
    "Y, valid_user_idxs = compute_basket_embeddings_train_only(user_baskets, reduced_X, id_to_index)\n",
    "\n",
    "print(f\"Generated embeddings for {len(Y)} users (dropped {len(user_baskets) - len(Y)} users with no valid items).\")\n",
    "\n",
    "distances, indices = nbrs.kneighbors(Y, n_neighbors=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12247a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(recommended_items, true_items, k):\n",
    "    \"\"\" \n",
    "    Calculates precision at k for the recommended items.\n",
    "    Parameters:\n",
    "        recommended_items (list): List of recommended items.\n",
    "        true_items (list): List of true items.\n",
    "        k (int): The cutoff rank (number of recommended items to consider).\n",
    "    \"\"\"\n",
    "    recommended_at_k = recommended_items if len(recommended_items) < k else recommended_items[:k]\n",
    "    true_positives = len(set(recommended_at_k) & set(true_items))\n",
    "    precision = true_positives / (len(recommended_at_k) if len(recommended_at_k) > 0 else 1)\n",
    "    return precision\n",
    "\n",
    "def recall_at_k(recommended_items, true_items, k):\n",
    "    \"\"\" \n",
    "    Calculates recall at k for the recommended items.\n",
    "    Parameters:\n",
    "        recommended_items (list): List of recommended items.\n",
    "        true_items (list): List of true items.\n",
    "        k (int): The cutoff rank (number of recommended items to consider).\n",
    "    \"\"\"\n",
    "    recommended_at_k = recommended_items if len(recommended_items) < k else recommended_items[:k]\n",
    "    true_positives = len(set(recommended_at_k) & set(true_items))\n",
    "    recall = true_positives / (len(true_items) if len(true_items) > 0 else 1)\n",
    "    return recall\n",
    "\n",
    "def fscore_at_k(recommended_items, true_items, k):\n",
    "    \"\"\"\n",
    "    Calculates F1-score at k for the recommended items.\n",
    "    \"\"\"\n",
    "    p = precision_at_k(recommended_items, true_items, k)\n",
    "    r = recall_at_k(recommended_items, true_items, k)\n",
    "\n",
    "    if p + r == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return 2 * p * r / (p + r)\n",
    "\n",
    "def evaluate_model(recommended_items_all, basket_test, k):\n",
    "    precisions, recalls, fscores = [], [], []\n",
    "\n",
    "    for row in basket_test.iter_rows():\n",
    "        user_id = row[0]\n",
    "        length = row[1]\n",
    "\n",
    "        true_items = row[2][:int(np.ceil(0.3 * length))]\n",
    "        recommended_items = recommended_items_all.get(user_id, [])\n",
    "\n",
    "        p = precision_at_k(recommended_items, true_items, k)\n",
    "        r = recall_at_k(recommended_items, true_items, k)\n",
    "        f = fscore_at_k(recommended_items, true_items, k)\n",
    "\n",
    "        precisions.append(p)\n",
    "        recalls.append(r)\n",
    "        fscores.append(f)\n",
    "\n",
    "    return np.mean(precisions), np.mean(recalls), np.mean(fscores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8d254f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def make_prediction_using_embeddings(baskets_df, valid_user_idxs, nn_indices, nn_distances, index_to_id, k=10):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        baskets_df: The polars dataframe containing User and Games list.\n",
    "        valid_user_idxs: The list returned by compute_basket_embeddings_robust.\n",
    "                         Maps the index in Y/nn_indices back to the row index in baskets_df.\n",
    "        nn_indices: The indices matrix from nbrs.kneighbors.\n",
    "        nn_distances: The distances matrix from nbrs.kneighbors.\n",
    "        index_to_id: Dict mapping matrix index -> Game ID.\n",
    "        k: Number of recommendations to return.\n",
    "    \"\"\"\n",
    "    recommended_items_all = {}\n",
    "    skip_counter = 0\n",
    "    too_short_counter = 0\n",
    "\n",
    "    row_to_array_idx = {row_idx: i for i, row_idx in enumerate(valid_user_idxs)}\n",
    "\n",
    "    for row_idx, row in enumerate(baskets_df.iter_rows()):\n",
    "        user_id = row[0]\n",
    "        all_games = row[2]\n",
    "\n",
    "        if row_idx not in row_to_array_idx:\n",
    "            skip_counter += 1\n",
    "            continue\n",
    "\n",
    "        length = len(all_games)\n",
    "        future = int(np.ceil(0.3 * length))\n",
    "        history = set(all_games[future:])\n",
    "\n",
    "        array_pos = row_to_array_idx[row_idx]\n",
    "\n",
    "        neighbor_matrix_indices = nn_indices[array_pos]\n",
    "\n",
    "\n",
    "        # recommendations are already sorted by distance, select top k not in history NOTE: it can happen that run out of candidates and end up with less than k recommendations\n",
    "        top_k = []\n",
    "        for mat_idx in neighbor_matrix_indices:\n",
    "\n",
    "            if mat_idx not in index_to_id:\n",
    "                continue\n",
    "\n",
    "            game_id = index_to_id[mat_idx]\n",
    "\n",
    "            if game_id not in history:\n",
    "                top_k.append(game_id)\n",
    "\n",
    "            if len(top_k) >= k:\n",
    "                break\n",
    "        if len(top_k) != k:\n",
    "            too_short_counter += 1\n",
    "        recommended_items_all[user_id] = top_k\n",
    "    if skip_counter > 0:\n",
    "        print(f\"Skipped {skip_counter} users (no valid embedding found).\")\n",
    "    if too_short_counter > 0:\n",
    "        print(f\"Could not generate {k} recommendations for {too_short_counter} users (not enough candidates).\")\n",
    "    return recommended_items_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed6631e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions for 418809 users...\n",
      "Skipped 20 users (no valid embedding found).\n",
      "Could not generate 1 recommendations for 9 users (not enough candidates).\n",
      "Skipped 20 users (no valid embedding found).\n",
      "Could not generate 3 recommendations for 106 users (not enough candidates).\n",
      "Skipped 20 users (no valid embedding found).\n",
      "Could not generate 5 recommendations for 540 users (not enough candidates).\n",
      "Skipped 20 users (no valid embedding found).\n",
      "Could not generate 7 recommendations for 3434 users (not enough candidates).\n",
      "Skipped 20 users (no valid embedding found).\n",
      "Could not generate 10 recommendations for 189883 users (not enough candidates).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.011222</td>\n",
       "      <td>0.006279</td>\n",
       "      <td>0.007363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>0.011068</td>\n",
       "      <td>0.007788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.013460</td>\n",
       "      <td>0.007137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.015285</td>\n",
       "      <td>0.006672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.004943</td>\n",
       "      <td>0.016719</td>\n",
       "      <td>0.006453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k  precision    recall    fscore\n",
       "0   1   0.011222  0.006279  0.007363\n",
       "1   3   0.007313  0.011068  0.007788\n",
       "2   5   0.005910  0.013460  0.007137\n",
       "3   7   0.005225  0.015285  0.006672\n",
       "4  10   0.004943  0.016719  0.006453"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(f\"Generating predictions for {len(valid_user_idxs)} users...\")\n",
    "\n",
    "ks = np.linspace(1, 10, 5, dtype=int)\n",
    "# ks = [3, 5, 7, 10]\n",
    "CV_results = {\"k\": [], \"precision\": [], \"recall\": [], \"fscore\": []}\n",
    "\n",
    "for k in ks:\n",
    "    recommended_items_all = make_prediction_using_embeddings(baskets_df=user_data, valid_user_idxs=valid_user_idxs, nn_indices=indices, nn_distances=distances, index_to_id=index_to_id, k=k)\n",
    "\n",
    "    precision, recall, fscores = evaluate_model(recommended_items_all, user_data, k)\n",
    "    CV_results[\"k\"].append(k)\n",
    "    CV_results[\"precision\"].append(precision)\n",
    "    CV_results[\"recall\"].append(recall)\n",
    "    CV_results[\"fscore\"].append(fscores)\n",
    "\n",
    "CV_results_df = pd.DataFrame(CV_results)\n",
    "CV_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24b13881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      " & k & precision & recall & fscore \\\\\n",
      "\\midrule\n",
      "0 & 1 & 0.011222 & 0.006279 & 0.007363 \\\\\n",
      "1 & 3 & 0.007313 & 0.011068 & 0.007788 \\\\\n",
      "2 & 5 & 0.005910 & 0.013460 & 0.007137 \\\\\n",
      "3 & 7 & 0.005225 & 0.015285 & 0.006672 \\\\\n",
      "4 & 10 & 0.004943 & 0.016719 & 0.006453 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(CV_results_df.to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
