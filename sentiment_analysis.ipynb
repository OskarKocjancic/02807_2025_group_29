{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d41f01bc",
   "metadata": {},
   "source": [
    "# Sentiment analysis of BoardGameGeek reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6457e4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f37bebd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All reviews: 26200012\n",
      "Unique games: 27865\n",
      "Reviews with text: 4215806\n",
      "Reviews with text and score <= 5: 720616\n",
      "Unique games that have > 0 review text : 27851\n"
     ]
    }
   ],
   "source": [
    "data = pl.read_csv(\"data/bgg-26m-reviews.csv\")\n",
    "print(\"All reviews:\", data.shape[0])\n",
    "print(\"Unique games:\", data.select(pl.col(\"ID\").n_unique()).item())\n",
    "data = data.filter(pl.col(\"comment\").is_not_null())\n",
    "data = data.sample(fraction=1)\n",
    "\n",
    "print(\"Reviews with text:\", data.shape[0])\n",
    "# print all reviews that have a low score\n",
    "print(\"Reviews with text and score <= 5:\", data.filter(pl.col(\"rating\") <= 5).shape[0])\n",
    "print(\"Unique games that have > 0 review text :\", data.select(pl.col(\"ID\").n_unique()).item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3ab80d",
   "metadata": {},
   "source": [
    "### Using pretrained emotions detection model trained on GoEmotions dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21f8eec",
   "metadata": {},
   "source": [
    "Run the script `emotions_gpu.py` to generate the file `data/bgg-26m-reviews-with-emotions.csv` which contains the emotion probabilities for each review in the BGG dataset. This notebook aggregates these probabilities by game ID and normalizes them to obtain a sentiment profile for each game.\n",
    "\n",
    "**Note** - processing the dataset takes a long time even with a GPU. The generated CSV file is also quite large (~3.5 GB). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1cb200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the emotion data obtained from the emotions_gpu.py script if it exists\n",
    "\n",
    "emotions_data = pl.read_csv(\"data/bgg-26m-reviews-with-emotions.csv\")\n",
    "\n",
    "positive_emotion_columns = [\"prob_admiration\", \"prob_amusement\", \"prob_approval\", \"prob_caring\", \"prob_curiosity\", \"prob_excitement\", \"prob_desire\", \"prob_gratitude\", \"prob_joy\", \"prob_love\", \"prob_pride\", \"prob_optimism\", \"prob_relief\"]\n",
    "\n",
    "negative_emotion_columns = [\"prob_anger\", \"prob_annoyance\", \"prob_disappointment\", \"prob_disapproval\", \"prob_disgust\", \"prob_embarrassment\", \"prob_fear\", \"prob_grief\", \"prob_nervousness\", \"prob_remorse\", \"prob_sadness\"]\n",
    "\n",
    "ambiguous_emotion_columns = [\"prob_confusion\", \"prob_realization\", \"prob_surprise\", \"prob_neutral\"]\n",
    "\n",
    "# aggregate emotions by game id\n",
    "all_emotion_cols = positive_emotion_columns + negative_emotion_columns + ambiguous_emotion_columns\n",
    "aggregated_emotions = emotions_data.group_by(\"ID\").agg(pl.col(all_emotion_cols).mean())\n",
    "\n",
    "# l1 normalize emotions\n",
    "aggregated_emotions = (\n",
    "    aggregated_emotions.with_columns(\n",
    "        pl.sum_horizontal(all_emotion_cols).alias(\"total_mass\")\n",
    "    )\n",
    "    .with_columns(\n",
    "        [(pl.col(c) / pl.col(\"total_mass\")).round(2).alias(c) for c in all_emotion_cols]\n",
    "    )\n",
    "    .drop(\"total_mass\")\n",
    ")\n",
    "\n",
    "\n",
    "#  create sum of negative,  positive and ambiguous emotions\n",
    "aggregated_emotions = aggregated_emotions.with_columns(\n",
    "    pl.sum_horizontal(positive_emotion_columns).round(2).alias(\"positive_emotion\"),\n",
    "    pl.sum_horizontal(negative_emotion_columns).round(2).alias(\"negative_emotion\"),\n",
    "    pl.sum_horizontal(ambiguous_emotion_columns).round(2).alias(\"ambiguous_emotion\"),\n",
    ")\n",
    "\n",
    "\n",
    "aggregated_emotions.write_csv(\"data/bgg-26m-aggregated-emotions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c45c9fb",
   "metadata": {},
   "source": [
    "The output of this notebook is saved to `data/bgg-26m-aggregated-emotions.csv`. and is provided in the repository to avoid the need for reprocessing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
